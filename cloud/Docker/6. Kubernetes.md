# Kubernetes

Make many servers act like one, not every solution needs orchestration

> Servers + change rate = benefit of orchestration

If Kubernetes, cloud or self-managed (Docker Enterprise, Rancher, OpenShift, Canonical, VMWare PKS)

## K8s or Kube terms
- Kubectl: CLI
- Node: single server
- Kubelet: Kubernetes agent running on nodes
- Control plane: set of containers that manage the cluster; API server, scheduler, control manager, etcd (distributed storage) and more; aka “manager”
- Install: from Docker desktop, MicroK8s, Katacoda.com, play-with-k8s.com
- Pod: one or more containers running together on one node
- Controller: creating/update pods and other objects
- Service: network endpoint to connect to a pod
- Namespace: filtered group of objects in cluster

Kubectl run, create, apply

Kebuctl run will be only for pod creation in v1.18

Similar to `docker run`, `docker compose`, `docker stack deploy`

```shell script
kubectl version
kubectl run my-nginx --image nginx
kubectl get pods

kubectl delete deployment my-nginx
kubectl get all

kubectl run nginx --image nginx # created a geployment named nginx before v1.18 (which creates a ReplicaSet, which creates a Pod)
kubectl run nginx --image nginx # creates a Pod named nginx in v1.18+
# Creating a Deployment in 1.18: kubectl create deployment nginx --image nginx
```

 
```shell script
kubectl run my-apache --image httpd
kubectl scale deploy/my-apache --replicas 2  # same as $kubectl scale deployment my-apache --replicas 2

kubectl logs deployment/my-apache --follow --tail 10  # only show one of the container's log
kubectl logs -l run=my-apache  # combine up to 5 pods

kubectl describe pod/{pod_id}  # similar to docker inspect

kubectl get pods -w  # watch, docker stats
kubectl delete pod/{pod_id}  # delete it, then it should re-create a new one
```


Kubernetes ports
> kubectl expose creates a service for existing pods, service is a stable address for pods


## Service types: 
- ClusterIP (default, for internal communication)
- NodePort(for outside)
- LoadBalancer: controls a LB endpoint external to the cluster, creates ClusterIP and NodePort; need support from infra
- ExternalName: internal talk to outside. Not often used
- Ingress: for http traffic

```shell script
kubectl create deployment httpenv --image=bretfisher/httpenv
kubectl scale deployment/httpenv --replicas=5
kubectl expose deployment/httpenv --port 8888  # ClusterIP, not accessible from outside, only to internal pods
kubectl get service
kube run -generator run-pod/v1 tmp-shell -rm -it -image bretfisher/netshoot - bash
$bash >> curl httpenv:8888
```

```shell script
kubectl expose deployment/httpenv --port 8888 --name httpenv-np --type NodePort  # also creates ClusterIP
curl localhost:32334

kubectl expose deployment/httpenv --port 8888 --name httpenv-lb --type LB # also creates ClusterIP and NodePort
curl localhost:8888
kubectl delete service {service_name}

kubectl get namespaces
curl <hostname>.<namespace>.svc.cluster.local

kubectl create deployment test --image nginx --dry-run -o yaml  # show deploy yaml
kubectl create job test --image nginx --dry-run -o yaml  # no replicas, no restart policy (never)
kubectl expose deployment/test --port 80 --dry-run -o yaml  # add ClusterIP
```


Most run features have moved to "create" cmd from 1.18

Declarative yaml
```shell script
kubectl apply -f filename.yml
```

Kind: get a list of resources that cluster supports
> kubectl api-resources

apiVersion: api versions that the cluster supports
> kubectl api-versions

Metadata: only name is required
Spec: where all the action is

```shell script
kubectl explain services --recursive  # all the keys kind supports
kubectl explain services.spec
kubectl explain services.spec.type
kubectl explain deployment.spec.template.spec.volumes.nfs.server    # subspec

kubectl get pods -l app=nginx  # filter by labels
```

Use labels and selectors to control which pods go to which nodes
Taints and tolerations also control node placement

## Storage
1. Containers are designed to be stateless
2. Use db-as-a-service whenever you can
3. Volumes: tied to lifecycle of a pod, multiple containers in a single pod share it
4. PersistentVolumes: created at the cluster level, multiple pods share it
5. CSI plugins are the new way to connect to storage (container storage interface)

- Ingress
- OSI layer 7 (http)
- Route outside connections based on hostname or URL, do this with 3rd party proxies

Dashboard
- Github.com/kubernetes/dashboard
- Or 3rd party (Rancher, Docker Ent, OpenShift), Clouds don't have it by default

- Docker security
- Kernel security
- Control group

> Do not run as root in workers: docker-node/8/Jessie/Dockerfile

- Snyk: code repo scanning
- Aqua microscanner, Trivy: free tool that scan container images

Distroless images: 

[12 Factor App](https://12factor.net)

letsencrypt.org: certificates for localhost

bretfisher/dogvscat
