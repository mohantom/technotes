# Kafka Streams
- 2020.05.27
- Udemy: Apache Kafka Series - Kafka Streams for Data Processing (2017)

1. Standard Java app
2. No need for separate cluster
3. Highly scalable, elastic, fault tolerant
4. Exactly once
5. One record at a time (no batch)


## Kafka streams vs Spark streaming, NiFi, Flink
- Micro batch vs per data streaming
- No additional cluster required
- Scales easily by adding java processes
- Exactly once (at least once for Spark streaming)
- NiFi is drap-n-drop
- [Kafka & Spark Streaming](https://www.quora.com/What-are-the-differences-and-similarities-between-Kafka-and-Spark-Streaming)

[Course code](https://courses.datacumulus.com/downloads/kafka-streams-sn2)


## Word Counter
- Stream
- Stream processor
- Topology
    - Source processor: take data directly from Kafka topic, does not transform data
    - Sink processor: no children, sends data directly to Kafka topic
 
### Configuration, can be done in code
- bootstrap.servers: need to connect to Kafka
- auto.offset.reset.config: set to 'earliest' to consume from start
- application.id: specific to Streams app, used for
    - Consumer group.id = application.id
    - default client.id prefix
    - prefix to internal changelog topics
- default.[key|value].serde: for serialization and deserilization of data

data in Kafka streams is <key, value>


### Topology
1. `Stream` from Kafka
2. `MapValues` lowercase
3. `FlatMapValues` split by space
4. `SelectKey` to apply a key
5. `GroupByKey` before aggregation
6. `Count` occurences in each group
7. `To` in order to write the results back to Kafka

// shutdown hook
```
Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
```


### intermediary topics
Kafka streams may eventually create internal intermediary topics

- repartition topics: when tranforming the key of streams
- changelog topics: when aggregations, Kafka streams save compacted data in the topics
- prefixed with app id
- user should not touch them 


### Scale up
start same number of apps as partitions


### TODO
0. Kafka on docker
1. WordCountProcessApp: Kafka consumer
2. WordCountOutputApp: Kafka consumer
3. WordCountInputApp: Kafka producer
