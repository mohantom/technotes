# Storm
- 2020.05.26
- Udemy: Learn By Example: Apache Storm (2017, Storm v1.0.2)

Workflow
> Spout -> split bolt x3 -> Count bolt x3 -> sort bolt x1

- Topology: one process config?
- Spout: like master?
- Bolt: like worker
- Nimbus: storm topology to coordinate process, like driver?
- Executor

## BaseRichSpout
- void open(Map conf, TopologyContext context, SpoutOutputCollector collector) // init
- void nextTuple()
- void declareOutputFields(OutputFieldsDeclared declarer)  // declare schema of tuple
- void ack(ObjectId msgId)
- void fail(Object msgId)

## BaseBasicBolt
- void prepare(Map stormConf, TopologyContext context) // eg, get db connection
- void execute(Tuple input, BasicOutputCollector collector)  // transformation logic
- void declareOuputFields(OutputFieldsDeclared declarer)
- void cleanup() // clean up if bolt is down

## Example: Hello World
Spout emit an integer continuously, bolt times it by 2

## Example: File processor
Similar to MSIM ETL with Spark
Spout reads file, emits each line to bolt, bolt appends " after bolt" to each line.

## Touples
- output fields are fixed for a Storm component
> declarer.declare(new Fields("id", "first_name", "last_name", "gender", "email")) // similar to Spark StructType

- local mode: 
```
LocalCluster cluster = new LocalCluster();
```

- cluster mode
```
StormSubmitter.submitTopology("My-First-Topology", conf, builder.createTopology());
cluster.submitTopology("My-First-Topology", conf, builder.createTopology());
```
1. set up Storm cluster with zookeeper
2. > storm jar "path_to_jar" Main_class_name
3. Storm UI to check jobs
