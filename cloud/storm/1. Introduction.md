# Storm
- 2020.05.26
- Udemy: Learn By Example: Apache Storm (2017, Storm v1.0.2)

- Pros
    - Realtime process

[Storm vs Flink](https://stackoverflow.com/questions/30699119/what-is-are-the-main-differences-between-flink-and-storm#:~:text=Storm%20and%20Flink%20have%20in,level%20API%20compared%20to%20Storm.&text=Storm%20guarantees%20at%2Dleast%2Donce,while%20Flink%20provides%20exactly%2Donce.)
Cloudera has recently announced the deprecation of Storm (in HDP). 
And simultaneously Flink was announced as its successor.
So, if you have usecases on storm, they will of course continue to work. 
But for new usecases I would look into Flink or other streaming engines.

Workflow
> Spout -> split bolt x3 -> Count bolt x3 -> sort bolt x1

- Topology: one process config?
- Spout: like master?
- Bolt: like worker
- Nimbus: storm topology to coordinate process, like driver?
- Executor

## BaseRichSpout
- void open(Map conf, TopologyContext context, SpoutOutputCollector collector) // init
- void nextTuple()
- void declareOutputFields(OutputFieldsDeclared declarer)  // declare schema of tuple for downstream
- void ack(ObjectId msgId)
- void fail(Object msgId)

## BaseBasicBolt
- void prepare(Map stormConf, TopologyContext context) // eg, get db connection
- void execute(Tuple input, BasicOutputCollector collector)  // transformation logic
- void declareOuputFields(OutputFieldsDeclared declarer)  // declare schema of tuple for downstream 
- void cleanup() // clean up if bolt is down

## Example: Hello World
Spout emit an integer continuously, bolt times it by 2

## Example: File processor
Similar to MSIM ETL with Spark
Spout reads file, emits each line to bolt, bolt appends " after bolt" to each line.

## Tuples
- output fields are fixed for a Storm component
> declarer.declare(new Fields("id", "first_name", "last_name", "gender", "email")) // similar to Spark StructType

- local mode: 
```
LocalCluster cluster = new LocalCluster();
```

- cluster mode
```
StormSubmitter.submitTopology("My-First-Topology", conf, builder.createTopology());
cluster.submitTopology("My-First-Topology", conf, builder.createTopology());
```
1. set up Storm cluster with zookeeper
2. > storm jar "path_to_jar" Main_class_name
3. Storm UI to check jobs
