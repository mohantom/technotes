# Flink
- 2020.06.03
- Udemy: Apache Flink | A REal Time & Hands-On course on Flink (2018, Flink v1.5)

[Storm vs Flink](https://stackoverflow.com/questions/30699119/what-is-are-the-main-differences-between-flink-and-storm#:~:text=Storm%20and%20Flink%20have%20in,level%20API%20compared%20to%20Storm.&text=Storm%20guarantees%20at%2Dleast%2Donce,while%20Flink%20provides%20exactly%2Donce.)
- High level api
- Exactly once

[Kafka Streams vs Flink](https://dzone.com/articles/kafka-stream-kstream-vs-apache-flink)

dataset for batch, datastream for streaming

- dataset is immutable, every operation creates a new dataset
- dose not support individual operations
- store list of its dependencies

## Installation
- [Flink](https://flink.apache.org)
- Maven project
    - flink-java
    - flink-streaming-java_2.11
    - flink-clients-2.11

## Dataset
- readTextFile(path)
- readCsvFile(path)
- readFileOfPrimitives(path, Class)
- readFileOfPrimitives(path, delimiter, Class)
- readHadoopFile(FileInputFormat, key, value, path)
- readSequenceFile(key, value, path)

```
  public static void main(String[] args) throws Exception {
    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
    ParameterTool params = ParameterTool.fromArgs(args);
    env.getConfig().setGlobalJobParameters(params);
    DataSet<String> text = env.readTextFile(params.get("input"));
    
    DataSet<String> filtered = text.filter(new FilterFunction<String>() {
      public boolean filter(String value) {
        return value.startsWith("N");
      }
    });
    DataSet<Tuple2<String, Integer>> tokenized = filtered.map(new Tokenizer());
    
    DataSet<Tuple2<String, Integer>> counts = tokenized.groupBy(new int[] { 0 }).sum(1);
    if (params.has("output")) {
      counts.writeAsCsv(params.get("output"), "\n", " ");
      env.execute("WordCount Example");
    }
  }
  
  public static final class Tokenizer implements MapFunction<String, Tuple2<String, Integer>> {
    public Tuple2<String, Integer> map(String value) {
      return new Tuple2(value, Integer.valueOf(1));
    }
  }
```

## Datastream
- readTextFile(path)
- readFile(fileInputFormat, path)
- readFile(fileInputFormat, path, watchType, internal, pathFilter)
- socketTextStream
- addSource: kafka, flume, twitter api, etc.

- writeAsText()
- writeAsCsv()
- writeUsingOutputFormat()
- writeSocket()
- addSource()
